# -*- coding: utf-8 -*-
"""indeed.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TnEJvO3AvEp4QwYHRTTT7sJEM1OAzzRS
"""

import requests
import bs4
from bs4 import BeautifulSoup
import pandas as pd
import time
import json

def get_url(position, location):
    """Generate url from position and location"""
    template = 'https://www.indeed.com/jobs?q={}&l={}'
    position = position.replace(' ', '+')
    location = location.replace(' ', '+')
    url = template.format(position, location)
    return url

url = get_url('senior accountant', 'charlotte nc')
print(url)

response = requests.get(url)

soup = BeautifulSoup(response.text, 'html.parser')

cards = soup.find_all('div', 'job_seen_beacon')

card = cards[0]

salary_tag = card.find_all('span', 'estimated-salary')
if salary_tag:
        salary = salary_tag.text.strip()
else:
        salary = 'none'  
salary

title = card.find('div','heading4').text

company = card.find('span', 'companyName').text
# print(company)

job_location = card.find('div', 'companyLocation').text

# job_description = card.find('li').text
# print(job_description)

summary = card.find('div','job-snippet').text.strip()

post_date = card.find('span', 'date').text

# card.find('div','metadata').text

# card.find('div', 'attribute_snippet').text

# card.find('div','metadata').text

# salary = card.find('span','estimated-salary').text

from google.colab import drive
drive.mount('/content/drive')

record = (title, company, job_location, summary, post_date, salary)
# print(record)

record

def get_record(card):
    """Extract job data from a single record"""
    
    title = card.find('div','heading4').text
    company = card.find('span', 'companyName').text
    summary = card.find('div','job-snippet').text.strip()
    job_location = card.find('div', 'companyLocation').text
    # today = datetime.today().strftime('%Y-%m-%
    post_date = card.find('span', 'date').text
    # job_url = 'https://www.indeed.com' + card.h2.a.get('href')

    # this does not exists for all jobs, so handle the exceptions
    salary_tag = card.find('div', 'attribute_snippet')
    if salary_tag:
        salary = salary_tag.text.strip()
    else:
        salary = ''  
        
    record = (title, company, summary,job_location, post_date, salary)
    return record

records = []

for card in cards:
    record = get_record(card)
    records.append(record)

while True:
    try:
        url = 'https://www.indeed.com' + soup.find('a', {'aria-label': 'Next'}).get('href')
    except AttributeError:
        break

    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    cards = soup.find_all('div', 'job_seen_beacon')

    for card in cards:
        record = get_record(card)
        records.append(record)

import csv
from datetime import datetime
import requests
import json
from bs4 import BeautifulSoup
import os


def get_url(position, location):
    """Generate url from position and location"""
    template = 'https://www.indeed.com/jobs?q={}&l={}'
    position = position.replace(' ', '+')
    location = location.replace(' ', '+')
    url = template.format(position, location)
    return url


def get_record(card):
    """Extract job data from a single record"""
    title = card.find('div','heading4').text
    company = card.find('span', 'companyName').text
    summary = card.find('div','job-snippet').text.strip()
    job_location = card.find('div', 'companyLocation').text
    post_date = card.find('span', 'date').text
    # availability_tag = card.find('div', 'attribute_snippet').text
    # today = datetime.today().strftime('%Y-%m-%
    # job_url = 'https://www.indeed.com' + card.h2.a.get('href')
    # this does not exists for all jobs, so handle the exceptions
     
    
  
    # this does not exists for all jobs, so handle the exceptions
    salary_tag = card.find('span', 'estimated-salary')
    if salary_tag:
        salary = salary_tag.text.strip()
    else:
        salary = 'None'

    availability_tag = card.find('div', 'attribute_snippet')

    if availability_tag:
      availability = availability_tag.text.strip()   
    else:
      availability = 'None'      
        
    record = (title, company, summary, job_location, post_date, salary,availability)
    return record


def main(position, location):
    """Run the main program routine"""
    records = []
    url = get_url(position, location)
    
    # extract the job data
    while True:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'lxml')
        cards = soup.find_all('div', 'job_seen_beacon')
        for card in cards:
            record = get_record(card)
            records.append(record)
        try:
            url = 'https://www.indeed.com' + soup.find('a', {'aria-label': 'Next'}).get('href')
        except AttributeError:
            break
        
    # save the job data
    with open('results.csv', 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['title', 'company', 'summary', 'job_location', 'post_date', 'salary','availability'])
        writer.writerows(records)
        # json.dump(records,f,ensure_ascii=False,indent=4)
        # f.close

# run the main program
main('python developer', 'charlotte nc')

